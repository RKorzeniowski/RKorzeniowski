# Attention and Transformer Architectures: A Mathematical Deep Dive

The advent of **attention mechanisms** and **Transformer architectures** has revolutionized deep learning, enabling breakthroughs in NLP, computer vision, and beyond. In this post, we dissect these concepts mathematically, explore their variants, and demonstrate their power through an image captioning model with attention visualization.

---

## 1. Attention Mechanisms: The Core Idea

Attention allows models to dynamically focus on relevant parts of input sequences. Unlike fixed-context RNNs, attention computes a **context vector** as a weighted sum of input elements, where weights are learned.

### 1.1 Key, Query, Value (KQV) Framework
- **Query (Q)**: Represents the current focus (e.g., a decoder token).
- **Key (K)**: Encodes input elements (e.g., encoder tokens).
- **Value (V)**: Contains actual information to aggregate.

**Scaled Dot-Product Attention**:

$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
$$

- $d_k$: Dimension of keys/queries (scaling stabilizes gradients).

**Pseudo-Code**:
```python
def attention(Q, K, V):
    scores = Q @ K.T / sqrt(d_k)
    weights = softmax(scores)
    return weights @ V
```

### 1.2 Soft vs. Hard Attention
- **Soft Attention**: Differentiable weighted sum (e.g., Transformer).
- **Hard Attention**: Selects one input element (non-differentiable; requires REINFORCE).

---

## 2. Multi-Head Attention

Multi-head attention projects K, Q, V into $h$ subspaces, allowing the model to jointly attend to different patterns.

**Mathematical Formulation**:

$$
\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, ..., \text{head}_h)W^O
$$

$$
\text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)
$$

- $W_i^Q, W_i^K, W_i^V \in \mathbb{R}^{d_{\text{model}} \times d_k}$: Learnable projections.
- $W^O \in \mathbb{R}^{h \cdot d_v \times d_{\text{model}}}$: Output projection.

**Intuition**: Each head learns unique attention patterns (e.g., syntax, semantics).

---

## 3. Self-Attention and Masking

- **Self-Attention**: Q, K, V come from the same sequence.
- **Masked Self-Attention**: In decoders, a causal mask ensures tokens attend only to past positions.

**Masking**:

$$
\text{Mask}(i, j) = \begin{cases}
0 & \text{if } j \leq i \\
-\infty & \text{otherwise}
\end{cases}
$$

Added to attention scores before softmax.

---

## 4. Positional Embeddings

Transformers lack inherent sequence order awareness. **Positional embeddings** inject positional information:

**Sinusoidal Encoding** (Original):

$$
PE_{(pos, 2i)} = \sin\left(\frac{pos}{10000^{2i/d_{\text{model}}}}\right)
$$

$$
PE_{(pos, 2i+1)} = \cos\left(\frac{pos}{10000^{2i/d_{\text{model}}}}\right)
$$

**Learned Embeddings**: Treat positions as learned indices.

---

## 5. Encoder-Decoder vs Encoder Only

### 5.1 Encoder
- Processes input via $N$ identical layers, each with:
  - Multi-head self-attention.
  - Position-wise feed-forward network (FFN).
  - Residual connections + LayerNorm.

### 5.2 Decoder
- Generates output autoregressively.
- **Encoder-Decoder Attention**: Queries from decoder, keys/values from encoder.

**FFN Layer**:

$$
\text{FFN}(x) = \text{ReLU}(xW_1 + b_1)W_2 + b_2
$$

### 5.3 Encoder Only
Models like BERT use encoder-only stacks with **bi-directional attention**, pretrained via masked language modeling (MLM).

---

## 6. Training and Loss Functions

**Cross-Entropy Loss**:

$$
\mathcal{L} = -\sum_{t=1}^T \log p(y_t | y_{&ltt}, x)
$$


**Label Smoothing**: Regularizes the model by penalizing over-confident predictions.

---

## 7. Putting It All Together: Transformer Flow

A typical Transformer consists of stacked layers combining multi-head self-attention, feed-forward networks, layer normalization, and residual connections. The flow of information through these layers allows the model to build rich representations of sequences.
Overview of Transformer Block (Encoder Example)

- Input Processing: The input tokens are embedded and summed with positional embeddings.
- Self-Attention Layer: The embedded sequence is processed with multi-head self-attention.
- Feed-Forward Network (FFN): A two-layer FFN with non-linear activations processes the output of the attention layer.
- Residual Connections and Layer Normalization: Residual connections add the input of each sublayer to its output, followed by layer normalization.
- Stacking Layers: Multiple encoder layers are stacked to form deep representations.

Pseudocode Outline for a Single Encoder Block

```python
def transformer_encoder_block(X, W_Q, W_K, W_V, W_O, FFN_weights, dropout_rate=0.1):
    # Multi-head self-attention sub-layer
    attn_output = multi_head_attention(X, X, X, num_heads=8, W_Q=W_Q, W_K=W_K, W_V=W_V, W_O=W_O)
    # Apply dropout and residual connection, then layer normalization
    X = layer_norm(X + dropout(attn_output, dropout_rate))
    
    # Feed-forward sub-layer
    ffn_output = feed_forward_network(X, FFN_weights)
    # Apply dropout and residual connection, then layer normalization
    X = layer_norm(X + dropout(ffn_output, dropout_rate))
    return X
```

---

## 8. A Cool Application: Image Captioning with Attention Visualization

One particularly cool implementation of Transformer flows is an image captioning model I developed. This model uses an encoder–decoder architecture where:

- Encoder: Processes the image features.
- Decoder: Generates a caption word by word using multi-head self-attention and encoder-decoder attention.

A standout feature of this implementation is its attention-based visualization: during caption generation, the model produces attention maps that highlight which regions of the image it “looks at” when generating each word in the caption. This offers a window into the model’s reasoning process.

For instance, when generating the word “surfer,” the attention visualization might show high "interest" over the region containing the human in the image. You can explore [Attention-based Image Captioning Visualization here](https://gitlab.com/korzeniowski.renard/image_caption_server). 

<div style="display: flex; align-items: center;">
  <div style="display: flex; align-items: center;">
    <img src="https://raw.githubusercontent.com/RKorzeniowski/rkorzeniowski/refs/heads/main/images/attn/attn_cat.png">
  </div>

  <div style="display: flex; align-items: center;">
    <img src="https://raw.githubusercontent.com/RKorzeniowski/rkorzeniowski/refs/heads/main/images/attn/attn_toilet.png">
  </div>

  <div style="display: flex; align-items: center;">
    <img src="https://raw.githubusercontent.com/RKorzeniowski/rkorzeniowski/refs/heads/main/images/attn/attn_bathroom.png">
  </div>
</div>

Video. 1. Cat images.

---

## 9. Conclusion

Attention and Transformers have redefined sequence modeling through parallelizable computation and dynamic context handling. From language translation to image captioning, their versatility and power continue to drive AI innovation.

**Further Reading**: [Attention Is All You Need (Vaswani et al., 2017)](https://arxiv.org/abs/1706.03762), [BERT](https://arxiv.org/abs/1810.04805), [Vision Transformers](https://arxiv.org/abs/2010.11929).
